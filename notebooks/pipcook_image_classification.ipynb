{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipcook_image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJtMrk5VGYMn",
        "colab_type": "text"
      },
      "source": [
        "## Environment Initialization\n",
        "This cell is used to initlialize necessary environments for pipcook to run, including Node.js 12.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIxSfN0KaMO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -P /tmp https://nodejs.org/dist/v12.18.1/node-v12.18.1-linux-x64.tar.xz\n",
        "!rm -rf /usr/local/lib/nodejs\n",
        "!mkdir -p /usr/local/lib/nodejs\n",
        "!tar -xJf /tmp/node-v12.18.1-linux-x64.tar.xz -C /usr/local/lib/nodejs\n",
        "!sh -c 'echo \"export PATH=/usr/local/lib/nodejs/node-v12.18.1-linux-x64/bin:\\$PATH\" >> /etc/profile'\n",
        "!rm -f /usr/bin/node\n",
        "!rm -f /usr/bin/npm\n",
        "!ln -s /usr/local/lib/nodejs/node-v12.18.1-linux-x64/bin/node /usr/bin/node\n",
        "!ln -s /usr/local/lib/nodejs/node-v12.18.1-linux-x64/bin/npm /usr/bin/npm\n",
        "!npm config delete registry\n",
        "\n",
        "import os\n",
        "PATH_ENV = os.environ['PATH']\n",
        "%env PATH=/usr/local/lib/nodejs/node-v12.18.1-linux-x64/bin:${PATH_ENV}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZDRzj2BGq8x",
        "colab_type": "text"
      },
      "source": [
        "## install pipcook cli tool\n",
        "pipcook-cli is the cli tool for pipcook for any operations later, including installing pipcook, run pipcook jobs and checking logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMeOA1CibuyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!npm install @pipcook/pipcook-cli -g\n",
        "!rm -f /usr/bin/pipcook\n",
        "!ln -s /usr/local/lib/nodejs/node-v12.18.1-linux-x64/bin/pipcook /usr/bin/pipcook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLoDFY8cG62x",
        "colab_type": "text"
      },
      "source": [
        "## Install Pipcook and start the daemon\n",
        "We will install pipcook in this cell and start the daemon. Pipcook daemon is the server to handle any pipcook jobs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB48puEBcfKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo pipcook init\n",
        "!sudo pipcook daemon start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64NgxpWhHcXK",
        "colab_type": "text"
      },
      "source": [
        "# Classify images of UI components\n",
        "\n",
        "## Background\n",
        "\n",
        "Have you encountered such a scenario in the front-end business: there are some images in your hand, and you want an automatic way to identify what front-end components these images are, whether it is a button, a navigation bar, or a form? This is a typical image classification task.\n",
        "\n",
        "> The task of predicting image categories is called image classification. The purpose of training the image classification model is to identify various types of images.\n",
        "\n",
        "This identification is very useful. You can use this identification information for code generation or automated testing.\n",
        "\n",
        "Taking code generation as an example, suppose we have a sketch design draft and the entire design draft is composed of different components. We can traverse the layers of the entire design draft. For each layer, use the model of image classification to identify what component each layer is. After that, we can replace the original design draft layer with the front-end component to generate the front-end code.\n",
        "\n",
        "Another example is in the scenario of automated testing. We need an ability to identify the type of each layer. For the button that is recognized, we can automatically click to see if the button works. For the list component that we recognize, we can automatically track loading speed to monitor performance, etc.\n",
        "\n",
        "## Examples\n",
        "\n",
        "For example, in the scenario where the forms are automatically generated, we need to identify which components are column charts or pie charts, as shown in the following figure:\n",
        "\n",
        "![image.png](https://img.alicdn.com/tfs/TB17LbHNQL0gK0jSZFAXXcA9pXa-293-172.png)\n",
        "\n",
        "![image.png](https://gw.alicdn.com/tfs/TB13I2LNQY2gK0jSZFgXXc5OFXa-442-369.png) \n",
        "\n",
        "After the training is completed, for each picture, the model will eventually give us the prediction results we want. For example, when we enter the line chart of Figure 1, the model will give prediction results similar to the following:\n",
        "\n",
        "```\n",
        "[[0.1, 0.9]]\n",
        "```\n",
        "\n",
        "At the same time, we will generate a labelmap during training. Labelmap is a mapping relationship between the serial number and the actual type. This generation is mainly due to the fact that our classification name is text, but before entering the model, we need to convert the text Into numbers. Here is a labelmap:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"column\": 0,\n",
        "  \"pie\": 1,\n",
        "}\n",
        "```\n",
        "\n",
        "First, why is the prediction result a two-dimensional array? First of all, the model allows prediction of multiple pictures at once. For each picture, the model will also give an array, this array describes the possibility of each classification, as shown in the labelmap, the classification is arranged in the order of column chart and pie chart, then corresponding to the prediction result of the model, We can see that the column chart has the highest confidence, which is 0.9, so this picture is predicted to be a column chart, that is, the prediction is correct.\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "When we are doing image classification tasks similar to this one, we need to organize our dataset in a certain format.\n",
        "\n",
        "We need to divide our dataset into a training set (train), a validation set (validation) and a test set (test) according to a certain proportion. Among them, the training set is mainly used to train the model, and the validation set and the test set are used to evaluate the model. The validation set is mainly used to evaluate the model during the training process to facilitate viewing of the model's overfitting and convergence. The test set is used to perform an overall evaluation of the model after all training is completed.\n",
        "\n",
        "In the training/validation/test set, we will organize the data according to the classification category. For example, we now have two categories, line and ring, then we can create two folders for these two category names, in the corresponding Place pictures under the folder. The overall directory structure is:\n",
        "\n",
        "- train\n",
        "   - ring\n",
        "      - xx.jpg\n",
        "      - ...\n",
        "   - line\n",
        "      - xxjpg\n",
        "      - ...\n",
        "   - column\n",
        "      - ...\n",
        "   - pie\n",
        "      - ...\n",
        "- validation\n",
        "   - ring\n",
        "      - xx.jpg\n",
        "      - ...\n",
        "   - line\n",
        "      - xx.jpg\n",
        "      - ...\n",
        "   - column\n",
        "      - ...\n",
        "   - pie\n",
        "      - ...\n",
        "- test\n",
        "   - ring\n",
        "      - xx.jpg\n",
        "      - ...\n",
        "   - line\n",
        "      - xx.jpg\n",
        "      - ...\n",
        "   - column\n",
        "      - ...\n",
        "   - pie\n",
        "      - ...\n",
        "\n",
        "We have prepared such a dataset, you can download it and check it outï¼š[Download here](http://ai-sample.oss-cn-hangzhou.aliyuncs.com/pipcook/datasets/component-recognition-image-classification/component-recognition-classification.zip).\n",
        "\n",
        "## Start Training\n",
        "\n",
        "After the dataset is ready, we can start training. Using Pipcook can be very convenient for the training of image classification. You only need to build the following pipeline:\n",
        "```json\n",
        "{\n",
        "  \"plugins\": {\n",
        "    \"dataCollect\": {\n",
        "      \"package\": \"@pipcook/plugins-image-classification-data-collect\",\n",
        "      \"params\": {\n",
        "        \"url\": \"http://ai-sample.oss-cn-hangzhou.aliyuncs.com/pipcook/datasets/component-recognition-image-classification/component-recognition-classification.zip\"\n",
        "      }\n",
        "    },\n",
        "    \"dataAccess\": {\n",
        "      \"package\": \"@pipcook/plugins-pascalvoc-data-access\"\n",
        "    },\n",
        "    \"dataProcess\": {\n",
        "      \"package\": \"@pipcook/plugins-image-data-process\",\n",
        "      \"params\": {\n",
        "        \"resize\": [224, 224]\n",
        "      }\n",
        "    },\n",
        "    \"modelDefine\": {\n",
        "      \"package\": \"@pipcook/plugins-tensorflow-mobilenet-model-define\",\n",
        "      \"params\": {\n",
        "        \"batchSize\": 8,\n",
        "        \"freeze\": false\n",
        "      }\n",
        "    },\n",
        "    \"modelTrain\": {\n",
        "      \"package\": \"@pipcook/plugins-image-classification-tensorflow-model-train\",\n",
        "      \"params\": {\n",
        "        \"epochs\": 15\n",
        "      }\n",
        "    },\n",
        "    \"modelEvaluate\": {\n",
        "      \"package\": \"@pipcook/plugins-image-classification-tensorflow-model-evaluate\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "Through the above plugins, we can see that they are used separately:\n",
        "\n",
        "1. **@pipcook/plugins-image-classification-data-collect** This plug-in is used to download the dataset that meets the image classification described above. Mainly, we need to provide the url parameter, and we provide the dataset address that we prepared above\n",
        "1. **@pipcook/plugins-pascalvoc-data-access** Now that we have downloaded the dataset, we need to convert the dataset to pipcook format so that we can use the model later\n",
        "1. **@pipcook/plugins-image-data-process** When performing image classification, we need to have some necessary operations on the original data. For example, image classification requires that all pictures are of the same size, so we use this plugin to resize the pictures to a uniform size\n",
        "1. **@pipcook/plugins-tensorflow-mobilenet-model-define**  We use this plugin to choose the model. The models are genrally defined in model-define plugins.\n",
        "1. **@pipcook/plugins-image-classification-tensorflow-model-train**  We use this plugin for training. This is a general plugin for image classification based on TensorFlow, which has nothing to do with the model selected in the previous stage.\n",
        "1. **@pipcook/plugins-image-classification-tensorflow-model-train** We use this plugin for evaluating. This step is to give out the performance of the model we have trained on previous step\n",
        "\n",
        "[mobilenet](https://arxiv.org/abs/1704.04861) is a lightweight model which can be trained on CPU. If you are using [resnet](https://arxiv.org/abs/1512.03385)ï¼Œsince the model is quite large, we recommend use to train on GPU. \n",
        "\n",
        "> CUDA, short for Compute Unified Device Architecture, is a parallel computing platform and programming model founded by NVIDIA based on the GPUs (Graphics Processing Units, which can be popularly understood as graphics cards).\n",
        "\n",
        "> With CUDA, GPUs can be conveniently used for general purpose calculations (a bit like numerical calculations performed in the CPU, etc.). Before CUDA, GPUs were generally only used for graphics rendering (such as through OpenGL, DirectX).\n",
        "\n",
        "Now let's run our image-classification job!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMNkCyFQeEml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo pipcook run https://raw.githubusercontent.com/alibaba/pipcook/master/example/pipelines/databinding-image-classification-resnet.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCz1sbHRH1IZ",
        "colab_type": "text"
      },
      "source": [
        "Often the model will converge at 10-20 epochs. Of course, it depends on the complexity of your dataset. Model convergence means that the loss (loss value) is low enough and the accuracy is high enough.\n",
        "\n",
        "After the training is completed, output will be generated in the current directory, which is a brand-new npm package, then we first install dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7yyYxV0nfOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd output && sudo npm install --unsafe-perm\n",
        "!wget http://ai-sample.oss-cn-hangzhou.aliyuncs.com/pipcook/dsw/predict.js"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGRe74t7jLzE",
        "colab_type": "text"
      },
      "source": [
        "Now we can predict. You can just have a try on code below to predict the image we provide. You can replace the image url with your own url to try on your own dataset. The predict result is in form of probablity of each category as we have explained before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGWgMXDBf_7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!node predict.js https://img.alicdn.com/tfs/TB1ekuMhQY2gK0jSZFgXXc5OFXa-400-400.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkyErWesELTg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Note that the prediction result we give is the probability of each category. You can process this probability to the result you want.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "In this way, the component recognition task based on the image classification model is completed. After completing the pipeline in our example, if you are interested in such tasks, you can also start preparing your own dataset for training. We have already introduced the format of the dataset in detail in the data preparation chapter. You only need to follow the file directory to easily prepare the data that matches our image classification pipeline."
      ]
    }
  ]
}
